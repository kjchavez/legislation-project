# Model params
num_layers: 2
unroll_length: 20
embedding_dim: 200
keep_prob: 1.0
vocab_size: 10003

# Initialization params
init_scale: 0.1

# Optimization params
max_grad_norm: 5
batch_size: 20
max_epoch: 4
max_max_epoch: 13
opt_method: "GradientDescentOptimizer"
opt_params:
  learning_rate: # Decaying
    decay_function: 'exponential_decay'
    decay_args:
      learning_rate: 2.0
      decay_steps: 32000
      decay_rate: 0.5
      staircase: true

